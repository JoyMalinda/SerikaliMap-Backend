'''
This file was generated by build_seed_from_sources.py
It parses the CSVs and GeoJSONs and uses your models to populate the database.
Run with: python seed.py

Make sure DATABASE_URL env var is set (postgres style), e.g.
export DATABASE_URL='postgresql://user:pass@host:5432/dbname'
'''

import os
import csv
import json
import ast
from pathlib import Path
from flask import Flask
from sqlalchemy import text
from dotenv import load_dotenv

from models import db, County, Constituency, Party, Official, Position, Term

# try shapely for geo handling
try:
    from shapely.geometry import shape, mapping
    from shapely.ops import unary_union
    from geoalchemy2.elements import WKTElement
    SHAPELY_AVAILABLE = True
except Exception:
    SHAPELY_AVAILABLE = False

BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / 'data'

FILES = {
    'counties_csv': DATA_DIR / 'kenyan_counties.csv',
    'constituency_csv': DATA_DIR / 'constituency_data.csv',
    'parties_csv': DATA_DIR / 'parties.csv',
    'presidents_csv' : DATA_DIR / 'presidents.csv',
    'senators_csv': DATA_DIR / 'senators.csv',
    'women_csv': DATA_DIR / 'women_rep.csv',
    'mps_csv': DATA_DIR / 'mps.csv',
    'governors_csv': DATA_DIR / 'governors.csv',
    'dep_govs_csv': DATA_DIR / 'dep_governors.csv',
    'constituencies_geojson': DATA_DIR / 'constituencies_geojson.json',
    'counties_geojson': DATA_DIR / 'counties_geojson.json',
}

# DB config
load_dotenv()

DATABASE_URL = os.getenv('DATABASE_URL') or os.getenv('DATABASE_URI')
if not DATABASE_URL:
    raise RuntimeError('Please set DATABASE_URL environment variable to your Postgres/Supabase connection string')

app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = DATABASE_URL
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False

# utility helpers

def parse_party_abbr(raw):
    if raw is None:
        return []
    raw = raw.strip()
    if not raw:
        return []
    
    # Case 1: already looks like a Python list string, e.g. "['UDA', 'WDM']"
    try:
        parsed = ast.literal_eval(raw)
        if isinstance(parsed, (list, tuple)):
            return list(parsed)
    except Exception:
        pass
    
    # Case 2: comma/semicolon separated abbreviations
    if ',' in raw or ';' in raw:
        return [p.strip() for p in raw.replace(';', ',').split(',') if p.strip()]
    
    # Case 3: single abbreviation
    return [raw]


def safe_int(val):
    try:
        if val is None or val == '':
            return None
        return int(float(val))
    except Exception:
        return val
    
def format_const_code(code):
    return str(code).zfill(3)


def load_geojson(path):
    if not Path(path).exists():
        return []
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)
    
def normalize_party_abbr(raw: str) -> str | None:
    if not raw:
        return None

    # strip braces and spaces
    cleaned = raw.strip().strip("{}").strip()

    # take the first alias if multiple given
    if "," in cleaned:
        cleaned = cleaned.split(",")[0].strip()

    return cleaned


with app.app_context():
    # initialize db (models module provided the db object)
    db.init_app(app)

    # Read CSVs to ensure they exist; the heavy lifting (inserting) will happen below.
    for k, p in FILES.items():
        if not Path(p).exists():
            print(f'Warning: {p} does not exist. Some sections may be skipped.')

    # --- TRUNCATE in safe order ---
    print('Truncating tables: terms -> officials -> parties -> constituencies -> counties -> positions')
    conn = db.session.connection()
    # Use raw SQL TRUNCATE for speed and to reset identity
    conn.execute(text('TRUNCATE TABLE terms RESTART IDENTITY CASCADE'))
    conn.execute(text('TRUNCATE TABLE officials RESTART IDENTITY CASCADE'))
    conn.execute(text('TRUNCATE TABLE parties RESTART IDENTITY CASCADE'))
    conn.execute(text('TRUNCATE TABLE constituencies RESTART IDENTITY CASCADE'))
    conn.execute(text('TRUNCATE TABLE counties RESTART IDENTITY CASCADE'))
    conn.execute(text('TRUNCATE TABLE positions RESTART IDENTITY CASCADE'))
    db.session.commit()

    # --- Positions: ensure canonical positions exist ---
    positions = [
        { 'name': 'Governor', 'level': 'county' },
        { 'name': 'Deputy Governor', 'level': 'county' },
        { 'name': 'Senator', 'level': 'county' },
        { 'name': 'Women Rep', 'level': 'county' },
        { 'name': 'MP', 'level': 'constituency' },
        { 'name': 'President', 'level': 'national' },
        { 'name': 'Vice President', 'level': 'national' },
        { 'name': 'Deputy President', 'level': 'national' },
    ]

    pos_map = {}
    for pos in positions:
        p = Position(name=pos['name'], level=pos['level'])
        db.session.add(p)
    db.session.commit()
    for p in Position.query.all():
        pos_map[p.name.lower()] = p

    # --- Counties ---
    import csv
    counties_geo = load_geojson(FILES['counties_geojson']) if Path(FILES['counties_geojson']).exists() else None
    counties_geo_index = {}
    if counties_geo:
        for feat in counties_geo.get('features', []):
            props = feat.get('properties', {})
            # use COUNTY_COD or COUNTY_COD or ID_ etc. We'll index by county name upper
            name = props.get('COUNTY_NAM') or props.get('COUNTY_NAM'.upper()) or props.get('COUNTY_NAM'.lower())
            if name:
                counties_geo_index[name.strip().upper()] = feat.get('geometry')

    with open(FILES['counties_csv'], newline='', encoding='utf-8-sig') as fh:
        reader = csv.DictReader(fh)
        for row in reader:
            try:
                row = {k.strip().lower(): v for k, v in row.items()}

                code = (row.get('code') or row.get('Code') or row.get('county_code'))
                name = (row.get('county') or row.get('County') or row.get('county_name') or '').strip()
                if not name:
                    continue
                population = (row.get('population_2019') or row.get('population') or row.get('population_2019'))
                area = (row.get('area_km2') or row.get('area') or row.get('area_km'))
                density = (row.get('pop_density') or row.get('pop_density') or row.get('pop_density'))

                geom = None
                geom_key = name.strip().upper()
                if SHAPELY_AVAILABLE and geom_key in counties_geo_index:
                    geom_shape = shape(counties_geo_index[geom_key])
                    # ensure multipolygon
                    if geom_shape.geom_type == 'Polygon':
                        mp = geom_shape.buffer(0)
                    else:
                        mp = geom_shape
                    geom = WKTElement(mp.wkt, srid=4326)

                county = County(name=name, code=code, population=population, area=area, population_density=density)
                if geom is not None:
                    county.geom = geom
                db.session.add(county)
            except Exception as e:
                print('Error processing county row', row, e)
    db.session.commit()
    print('Inserted counties:', County.query.count())

    # Build county lookup by name (upper) and by code
    county_by_name = {c.name.strip().upper(): c for c in County.query.all()}
    county_by_code = {str(c.code): c for c in County.query.all() if c.code is not None}

    # --- Constituencies ---
    import geojson
    constituencies_geo = None
    if Path(FILES['constituencies_geojson']).exists():
        with open(FILES['constituencies_geojson'], 'r', encoding='utf-8') as f:
            constituencies_geo = json.load(f)

    # index constituencies geo by name upper and by code
    const_geo_by_name = {}
    const_geo_by_code = {}
    if constituencies_geo:
        for feat in constituencies_geo.get('features', []):
            props = feat.get('properties') or {}
            cname = (props.get('CONSTITUEN') or props.get('CONSTITUEN'.upper()) or props.get('CONSTITUEN'.lower()) or '').strip()
            code = props.get('CONST_CODE') or props.get('CONST_CODE'.upper()) or props.get('CONST_CODE'.lower())
            if cname:
                const_geo_by_name[cname.upper()] = feat
            if code:
                const_geo_by_code[str(code)] = feat

    # load constituency supplemental CSV for population/area/density
    constituency_extra = {}
    with open(FILES['constituency_csv'], newline='', encoding='utf-8') as fh:
        reader = csv.DictReader(fh)
        for row in reader:
            name = (row.get('Constituency') or row.get('CONSTITUENCY') or '').strip()
            if not name or name.upper() == 'TOTAL':
                continue
            constituency_extra[name.upper()] = {
                'population': (row.get('Population') or row.get('population')),
                'area': (row.get('Area_sq_km') or row.get('Area') or row.get('area')),
                'density': (row.get('Density') or row.get('density')),
            }

    # create constituencies from geojson (authoritative)
    for key, feat in (const_geo_by_name.items()):
        try:
            props = feat.get('properties') or {}
            cname = (props.get('CONSTITUEN') or props.get('CONSTITUEN'.upper()) or '').strip()
            ccode = format_const_code(props.get('CONST_CODE') or props.get('const_code'))
            county_code = format_const_code(props.get('COUNTY_COD') or props.get('COUNTY_COD'.upper()) or props.get('COUNTY_COD'.lower()))
            county_obj = None
            if county_code:
                county_obj = county_by_code.get(str(county_code))
            if not county_obj:
                # try to match by county name (COUNTY_NAM)
                county_name = (props.get('COUNTY_NAM') or props.get('COUNTY_NAM'.upper()) or '').strip()
                if county_name:
                    county_obj = county_by_name.get(county_name.upper())
            if not county_obj:
                # last resort: try user-supplied 'county' column in constituency_csv (not ideal)
                # skip if no county found
                print('Warning: no county found for constituency', cname, 'skipping')
                continue

            population = None
            area = None
            density = None
            extra = constituency_extra.get(cname.upper())
            if extra:
                population = extra.get('population')
                area = extra.get('area')
                density = extra.get('density')

            geom = None
            if SHAPELY_AVAILABLE:
                geom_shape = shape(feat.get('geometry'))
                if geom_shape.geom_type == 'Polygon':
                    mp = geom_shape.buffer(0)
                else:
                    mp = geom_shape
                try:
                    geom = WKTElement(mp.wkt, srid=4326)
                except Exception:
                    geom = None

            cons = Constituency(name=cname, county_id=county_obj.id, code=str(ccode) if ccode else None,
                                population=population, area=area, population_density=density)
            if geom is not None:
                cons.geom = geom
            db.session.add(cons)
        except Exception as e:
            print('Constituency insert error', e)
    db.session.commit()
    print('Inserted constituencies:', Constituency.query.count())

    # Build lookups for constituency by name and by code
    constituency_by_name = {c.name.strip().upper(): c for c in Constituency.query.all()}
    constituency_by_code = {str(c.code): c for c in Constituency.query.all() if c.code is not None}

    # --- Parties ---
    party_by_name = {}
    party_by_abbrev = {}

    with open(FILES['parties_csv'], newline='', encoding='utf-8') as fh:
        reader = csv.DictReader(fh)
        for row in reader:
            name = (row.get('Party Name') or row.get('name') or '').strip()
            if not name:
                continue
            abbr_raw = row.get('abbreviation') or row.get('abbrev') or ''
            abbr = parse_party_abbr(abbr_raw)
            party = Party(name=name, abbreviation=abbr)
            db.session.add(party)

            party_by_name[name.upper()] = party
            for ab in abbr:
                party_by_abbrev[ab.upper()] = party

    db.session.commit()
    print('Inserted parties:', Party.query.count())
    party_by_name = {p.name.strip().upper(): p for p in Party.query.all()}

    # Helper to create Official (avoid duplicates by name) and Term
    def upsert_official(name, gender, photo_url):
        name_key = name.strip()
        existing = Official.query.filter(Official.name.ilike(name_key)).first()
        if existing:
            return existing
        o = Official(name=name.strip(), gender=gender or 'other', photo_url=photo_url or 'https://placehold.co/600x800?text=Portrait')
        db.session.add(o)
        db.session.flush()
        return o

    def create_term_for_official(
        official_obj,
        position_name,
        party_abbr,
        county_name=None,
        constituency_name=None,
        nomination_type=None,
        start_year=None,
        end_year=None
    ):
    # Resolve position
        pos = pos_map.get(position_name.lower())
        if not pos:
            print('No position', position_name, 'found; skipping term for', official_obj.name)
            return None

        # Resolve party by abbreviation
        party_obj = None
        if party_abbr:
            party_obj = party_by_abbrev.get(str(party_abbr).strip().upper())

        if not party_obj:
            # attempt fuzzy match: check if abbreviation appears in any stored list
            for abbr, pobj in party_by_abbrev.items():
                if party_abbr and party_abbr.strip().upper() in abbr:
                    party_obj = pobj
                    break

        if not party_obj:
            if party_abbr and party_abbr.strip().lower() in ["independent", "ind"]:
                print(f"Info: {official_obj.name} is Independent → setting party_id NULL")
                party_obj = None
            else:
                print('Warning: party not found for', official_obj.name, 'party abbr=', party_abbr)

        # Resolve county/constituency ids
        county_id = None
        constituency_id = None
        if county_name:
            county_obj = county_by_name.get(county_name.strip().upper())
            if county_obj:
                county_id = county_obj.id
        if constituency_name:
            constituency_obj = constituency_by_name.get(constituency_name.strip().upper())
            if constituency_obj:
                constituency_id = constituency_obj.id

        # Create the term
        term = Term(
            official_id=official_obj.id,
            position_id=pos.id,
            party_id=party_obj.id if party_obj else None,
            start_year=start_year or 2022,
            end_year=end_year,
            county_id=county_id,
            constituency_id=constituency_id,
            nomination_type=nomination_type,
        )
        db.session.add(term)
        db.session.flush()
        return term
    
    # --- Presidents & Deputies ---
    
    with open(FILES['presidents_csv'], newline='', encoding='utf-8') as fh:
        reader = csv.DictReader(fh)
        for row in reader:
            name = row.get('name', '').strip()
            position = row.get('position', '').strip()
            party = row.get('party', '').strip()
            gender = row.get('gender').strip().lower()
            start_year = safe_int(row.get('start_year'))
            end_year = safe_int(row.get('end_year'))
            photo = row.get('image_path') or ''

            if not name or not position:
                continue

            off = upsert_official(name=name, gender=gender, photo_url=photo)
            create_term_for_official(
                off,
                position_name=position,
                party_abbr=party,
                start_year=start_year,
                end_year=end_year
            )
    db.session.commit()
    print('Inserted presidents & deputies')

    # --- Governors ---
    with open(FILES['governors_csv'], newline='', encoding='utf-8') as fh:
        reader = csv.DictReader(fh)
        for row in reader:
            name = (row.get('name') or row.get('Name') or '').strip()
            county = (row.get('county') or row.get('County') or '').strip()
            party = (row.get('party') or row.get('Party') or '').strip()
            photo = (row.get('image_url') or row.get('image') or '')
            gender=(row.get('gender')).strip().lower() 
            if not name or not county:
                print('Skipping governor row (missing name or county):', row)
                continue
            off = upsert_official(name=name, gender=gender, photo_url=photo)
            # create term at county level
            create_term_for_official(off, 'Governor', party_abbr=party, county_name=county)
    db.session.commit()

    # --- Deputy Governors ---
    with open(FILES['dep_govs_csv'], newline='', encoding='utf-8') as fh:
        reader = csv.DictReader(fh)
        for row in reader:
            county_name = row.get('county', '').strip()
            name = row.get('name', '').strip()
            gender = row.get('gender', '').strip().lower()
            photo = row.get('photo_url', '').strip()

            county = County.query.filter(
                County.name.ilike(county_name)
            ).first()

            if not county:
                print(f"Warning: county '{county_name}' not found for Deputy Governor {name}")
                continue

            # ✅ Find Governor’s most recent term to copy party
            governor = (
                Official.query.join(Term)
                .join(Position)
                .filter(Position.name == "Governor", Term.county_id == county.id)
                .order_by(Term.start_year.desc().nullslast())
                .first()
            )

            if not governor or not governor.terms:
                print(f"Warning: no Governor found for {county_name}, skipping Deputy Governor {name}")
                continue

            governor_party = governor.terms[-1].party  # latest party
            dep_party = normalize_party_abbr(governor_party.abbreviation) if governor_party else None

            off = upsert_official(name=name, gender=gender, photo_url=photo)

            # ✅ Use the Governor’s party
            create_term_for_official(
                off,
                position_name="Deputy Governor",
                county_name=county_name,
                party_abbr=dep_party,
                start_year=2022,
                end_year=None,
            )
    db.session.commit()

    # --- Senators ---
    with open(FILES['senators_csv'], newline='', encoding='utf-8') as fh:
        reader = csv.DictReader(fh)
        for row in reader:
            name = (row.get('name') or row.get('Name') or '').strip()
            county = (row.get('county') or row.get('County') or '').strip()
            party = (row.get('party') or row.get('Party') or '').strip()
            photo = (row.get('local_image_path') or row.get('image') or row.get('image_url') or '')
            status = (row.get('status') or '').strip().lower()
            gender = (row.get('gender')).strip().lower()
            if not name:
                continue
            if name.strip().upper().startswith('VACANT'):
                continue
            off = upsert_official(name=name, gender=gender, photo_url=photo)
            # nominated senators may have county = 'Nominated' or blank; allow that
            county_name = None if county.strip().upper() in ('', 'NOMINATED') else county
            create_term_for_official(off, 'Senator', party_abbr=party, county_name=county_name)
    db.session.commit()

    # --- Women Reps ---
    with open(FILES['women_csv'], newline='', encoding='utf-8') as fh:
        reader = csv.DictReader(fh)
        for row in reader:
            name = (row.get('name') or row.get('Name') or '').strip().title()
            county = (row.get('county') or row.get('County') or '').strip()
            party = (row.get('party') or row.get('Party') or '').strip()
            photo = (row.get('image_url') or row.get('image') or row.get('image_local_path') or '')
            if not name:
                continue
            off = upsert_official(name=name, gender='female', photo_url=photo)
            create_term_for_official(off, 'Women Rep', party_abbr=party, county_name=county)
    db.session.commit()

    # --- MPs ---
    with open(FILES['mps_csv'], newline='', encoding='utf-8') as fh:
        reader = csv.DictReader(fh)
        for row in reader:
            name = (row.get('name') or row.get('Name') or '').strip()
            party = (row.get('party') or row.get('Party') or '').strip()
            constituency = (row.get('constituency') or row.get('Constituency') or '').strip()
            county = (row.get('county') or row.get('County') or '').strip()
            status = (row.get('status') or '').strip().lower()
            photo = (row.get('image_local_path') or row.get('image') or row.get('image_url') or '')

            if not name:
                continue
            if name.strip().upper().startswith('VACANT'):
                # if seat marked VACANT, skip creating an official/term
                continue
            # Some rows are truly empty for location; skip term creation (but still create official)
            if not any([party, constituency, county, photo]):
                # no data to build a term from; create official only and continue
                off = upsert_official(name=name, gender='other', photo_url=photo)
                print('Created official without term (insufficient location/party data):', name)
                continue

            off = upsert_official(name=name, gender='other', photo_url=photo)
            # For nominated MPs, constituency/county could be blank; still create term with nulls
            constituency_name = None if constituency.strip() == '' else constituency
            county_name = None if county.strip() == '' else county
            # If constituency is present but not matched in DB, still create term with null constituency
            create_term_for_official(off, 'MP', party_abbr=party, county_name=county_name, constituency_name=constituency_name)
    db.session.commit()

    print('Seeding complete.')
    print('Officials:', Official.query.count())